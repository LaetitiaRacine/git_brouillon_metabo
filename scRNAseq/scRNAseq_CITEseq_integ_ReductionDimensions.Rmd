---
title: "scRNAseq_CITEseq_integ_ReductionDimension"
author: "Laëtitia Racine"
date: "2022-10-03"
subtitle: "Dernière modification : `r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    code_folding: "show"
    toc: false
    theme: journal
---

```{r, Setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, Dependencies, message=F, warning=F}

library(Seurat)
library(dplyr)
library(ggplot2)

```

```{r, Working directories and external script}

directory = "/home/rparmentier/Bureau/Git_Metabo_Analysis/"
directory_exp = paste0(directory, "exp/")
directory_data = paste0(directory, "data/scRNAseq/")
directory_bin = paste0(directory, "bin/")

# Create a unique folder for output corresponding to the date of the day
current_date = format(Sys.time(), "%Y%m%d")
dir.create(path = paste0(directory_exp,"scRNAseq_CITEseq_integ_ReductionDimensions/"))
dir.create(path = paste0(directory_exp,"scRNAseq_CITEseq_integ_ReductionDimensions/", current_date))
directory_output = paste0(directory_exp, "scRNAseq_CITEseq_integ_ReductionDimensions/", current_date, "/")

# Load external script with functions and constantes 
source(file = paste0(directory_bin, "functions_constantes.R"))

```

```{r, Input loading}

dir = pic_last_dir(paste0(directory_exp, "scRNAseq_CITEseq_integ_IntegrateConditions/"))
# Object with cc regression
seurat_obj_cc = readRDS(paste0(dir, "/", "integrate_seurat_obj_qc_norm_ccr.rds"))
# Object without cc regression
seurat_obj = readRDS(paste0(dir, "/", "integrate_seurat_obj_qc_norm.rds"))

```




<!-- ### .Vérification du nombre d'UMI par gènes      => à mettre dans filter ???? -->

<!-- Nombre de gènes représentés par un seul UMI -->
<!-- ```{r} -->
<!-- rna_count = as.data.frame(obj@assays$RNA@counts) -->

<!-- tab_umi = data.frame(genes = as.character(), -->
<!--                      nb_cell_detect = as.numeric(), -->
<!--                      total_umi = as.numeric(), -->
<!--                      moyUMI_cell = as.numeric()) -->

<!-- library(tidyverse) -->
<!-- library(matrixStats) -->

<!-- tab = rna_count[10:15, 10:15] -->
<!-- tab = tab %>% mutate(totalUMI = rowSums(.)) -->
<!-- tab = tab %>% mutate(moyUMI_cell = totalUMI/ncol(tab)) -->
<!-- tab = tab %>% mutate(medianUMI_cell = rowMedians(as.matrix(tab[,c(-ncol(tab), -ncol(tab)-1)]))) -->
<!-- tab = tab %>% tibble::rownames_to_column(var = "gene") -->

<!-- gene1UMI = nrow(tab%>%filter(totalUMI==1)) # gene détecté dans une seule cellule avec un seul UMI  -->
<!-- geneMed5UMI = nrow(tab%>%filter(medianUMI_cell==5)) -->
<!-- ``` -->



**Doublets** : il existe un pourcentage d'erreur d'encapsulation des cellules en fonction du nombre inséré dans la puce. Il est en effet possible que des deux cellules aient été emprisonnées dans le même GEM, leurs transcrits auront donc tous le même barcode et seront considérés comme appartenant à une seule cellules. Il convient ainsi de nettoyer le jeu de données en enlevant les possibles doublets présents

# .Visualisation de l'effet des filtres 

<!-- **Filtre 1 : les doublets** -->
<!-- ```{r, doublet_dimPlot, results = 'hold', fig.width=18, fig.height=18, fig.fullwidth=TRUE} -->
<!-- # name of the DF prediction can change, so extract the correct column name. -->
<!-- DF.name = colnames(merge_allcond_filter@meta.data)[grepl("DF.classification",colnames(merge_allcond_filter@meta.data))] -->
<!-- # vizualisation -->
<!-- DimPlot(merge_allcond_filter, split.by = "orig.ident", group.by = DF.name, reduction = "umap", ncol = 3) + NoAxes() -->
<!-- ``` -->


<!-- ### .Vérification de la présence de doublets (objet sur lesquels les autres filtres ont été appliqués) -->

<!-- => à faire au tout tout début du workflow ! avant de merge les fichiers ! -->
<!-- https://www.youtube.com/watch?v=NqvAS4HgmrE -->


<!-- https://nbisweden.github.io/workshop-scRNAseq/labs/compiled/seurat/seurat_01_qc.html#Predict_doublets -->

<!-- il existe un pourcentage d'erreur d'encapsulation des cellules en fonction du nombre inséré dans la puce. Il est en effet possible que des deux cellules aient été emprisonnées dans le même GEM, leurs transcrits auront donc tous le même barcode et seront considérés comme appartenant à une seule cellules. Il convient ainsi de nettoyer le jeu de données en enlevant les possibles doublets présents. -->
<!-- On utilise ici le package DoubletFinder mais d'autres outils existent (ex : Scrublet..). Ce détecteur de doublets nécessite une approximation du nombre de doublets attendus. Dans notre cas, on a inséré environ 9000 cellules par puits pour espérer avoir 5000 cellules par puits dans l'analyse. On estime donc le probable taux de doublet à environ 4,6% (voir notice protocole 10X). -->
<!-- Dans l'exemple, il est indiqué : "Ideally doublet prediction should be run on each sample separately, especially if your different samples have different proportions of celltypes. In this case, the data is subsampled so we have very few cells per sample and all samples are sorted PBMCs so it is okay to run them together." On décide de le faire également sur le fichier avec toutes les conditions. => à discuter ?!?  -->

<!-- On travaille à partir de l'objet contenant tous les filtres.  -->

<!-- ```{r, doublet_dimPlot, results = 'hold', fig.width=18, fig.height=18, fig.fullwidth=TRUE} -->
<!-- # name of the DF prediction can change, so extract the correct column name. -->
<!-- DF.name = colnames(obj_nbG_pMT_pRB_rmMT@meta.data)[grepl("DF.classification",colnames(obj_nbG_pMT_pRB_rmMT@meta.data))] -->
<!-- # vizualisation -->
<!-- DimPlot(obj_nbG_pMT_pRB_rmMT, split.by = "orig.ident", group.by = DF.name, reduction = "umap", ncol = 3) + NoAxes() -->
<!-- ``` -->

<!-- ```{r, doubletFinder, results = 'hold', fig.width=18, fig.height=18, fig.fullwidth=TRUE} -->

<!-- # define the expected number of doublet cells -->
<!-- nExp <- round(ncol(obj_nbG_pMT_pRB_rmMT) * 0.046)  # expect 4,6% doublets -->
<!-- merge_allcond_filter <- doubletFinder_v3(obj_nbG_pMT_pRB_rmMT, pN = 0.25, pK = 0.09, nExp = nExp, PCs = 1:30) -->

<!-- # save  -->
<!-- saveRDS(obj_nbG_pMT_pRB_rmMT, file = paste0(dir_output, "data_allcond_doubletfinder.rds")) -->
<!-- ``` -->

<!-- Il convient ensuite de vérifier si les doublets identifiés par le package sont réellement des doublets. On s'attend à ce que deux cellules contiennent plus de gènes exprimés qu'une seule cellule. Le plot ci-dessous montre que c'est bien le cas pour les doublets détectés. On peut donc se fier à la prédiction de l'outil. -->
<!-- ```{r, doublet_features, results = 'hold', fig.width=8, fig.height=6} -->
<!-- VlnPlot(obj_nbG_pMT_pRB_rmMT, features = "nFeature_RNA", group.by = DF.name, pt.size = 0.1) -->
<!-- ``` -->

<!-- ```{r, filter1} -->
<!-- # Application du filtre -->
<!-- obj_nbG_pMT_pRB_rmMT = obj_nbG_pMT_pRB_rmMT[, obj_nbG_pMT_pRB_rmMT@meta.data[, DF.name] == "Singlet"] -->
<!-- obj_nbG_pMT_pRB_rmMT[["filter_rmDB"]] = "rm Doublet"  -->
<!-- ``` -->

<!-- ```{r, filter1_tab-recap} -->
<!-- # Tableau récapitulatif de l'impact du filtre sur le nombre de cellules et de gènes -->
<!-- tab_cell = as.data.frame(table(obj_nbG_pMT_pRB_rmMT@meta.data$orig.ident)) %>%  -->
<!--   dplyr::rename(condition = "Var1", filter1_keep = "Freq") %>%  -->
<!--   dplyr::mutate(category = "cells", .after = "condition") -->

<!-- tab_genes = tab_genes_create(obj = obj_nbG_pMT_pRB_rmMT, name_filter = "filter1_keep") -->
<!-- tab = full_join(tab_genes, tab_cell, by = c("condition", "category", "filter1_keep")) -->
<!-- stat_tab = full_join(stat_tab, tab, by = c("condition", "category")) -->
<!-- ``` -->

<!-- ```{r, mergeallcondfilter1_save} -->
<!-- saveRDS(merge_allcond_filter, file = paste0(dir_output, "dataset_Seurat_allcond_filter1.rds")) -->
<!-- ``` -->






<!-- Travail à partir d'un seul objet Seurat normalisé. -->

<!-- # Réduction de dimensions par PCA -->

<!-- *Calcul de la PCA* -->
<!-- ```{r} -->

<!-- list_obj = lapply(list_obj, function(x) { RunPCA(object = x,  -->
<!--                                                  assay = "SCT", -->
<!--                                                  npcs = 100,  -->
<!--                                                  # reduction.name = "pca.LogNorm",  -->
<!--                                                  verbose = TRUE) }) -->

<!-- ``` -->
<!-- *Visualisation de la PCA en 2D* -->
<!-- ```{r,  results='hold', fig.width=18, fig.height=10, fig.fullwidth=TRUE} -->
<!-- for (i in 1:length(list_obj)) { -->

<!--   obj = list_obj[[i]] -->
<!--   name_obj = names(list_obj)[i] -->

<!--   logNorm_pca_plot = DimPlot(object = obj, group.by = "orig.ident", reduction = "pca") + NoLegend() + ggtitle(name_obj) -->
<!--     # logNorm_pca_plot = DimPlot(object = obj, group.by = "orig.ident", reduction = "pca.LogNorm") + NoLegend() + ggtitle(name_obj) -->
<!--   logNorm_pca_split_plot = DimPlot(object = obj, group.by = "orig.ident", split.by = "orig.ident", reduction = "pca") -->
<!--     # logNorm_pca_split_plot = DimPlot(object = obj, group.by = "orig.ident", split.by = "orig.ident", reduction = "pca.LogNorm") -->

<!--   ggsave(plot = logNorm_pca_plot|logNorm_pca_split_plot, -->
<!--   filename =  paste0(dir_output, "plot_logNorm_pca_", name_obj, ".png"), -->
<!--   height = 6, width = 18) -->

<!--   print(logNorm_pca_plot | logNorm_pca_split_plot) -->

<!-- } -->
<!-- ``` -->
<!-- *Choix des dimensions à conserver* -->

<!-- On commence par tracer des "elbow plots" qui permettent de déterminer visuellement un nombre de dimensions à conserver (approximatif). Les dimensions sont rangées selon le pourcentage de variance qu'elles expliquent. On souhaite conserver les dimensions qui expliquent le plus la variance. pour cela, on repère lendroit où la courbe fait un coude.  -->

<!-- ```{r, results='hold', fig.width=18, fig.height=10, fig.fullwidth=TRUE} -->

<!-- for (i in 1:length(list_obj)) { -->

<!--   obj = list_obj[[i]] -->
<!--   name_obj = names(list_obj)[i] -->

<!--   # logNorm_elb_plot = ElbowPlot(object = obj, ndims = 100, reduction = "pca.LogNorm") +  -->
<!--   #   geom_vline(xintercept = 30, color = "red", size = 1) +  -->
<!--   #   ggtitle(name_obj) + -->
<!--   #   theme(plot.background = element_rect(fill = "white")) -->

<!--     logNorm_elb_plot = ElbowPlot(object = obj, ndims = 100, reduction = "pca") +  -->
<!--     geom_vline(xintercept = 30, color = "red", size = 1) +  -->
<!--     ggtitle(name_obj) + -->
<!--     theme(plot.background = element_rect(fill = "white")) -->

<!--   ggsave(plot = logNorm_elb_plot,  -->
<!--          filename = paste0(dir_output, "plot_logNorm_elb_", name_obj, ".png"),  -->
<!--          height = 4, width = 8) -->

<!--   print(logNorm_elb_plot) -->

<!-- } -->

<!-- ``` -->

<!-- De façon approximative, on observe que les 30 premières dimensions représentent la majorité de la variance donc on ne s'occupe plus des autres dimensions. Pour valider ce choix, on réalise le test statistique du JackStraw.  -->

<!-- ```{r, results='hold', fig.width=18, fig.height=10, fig.fullwidth=TRUE} -->

<!-- list_obj = lapply(list_obj, function(x) {  -->
<!--   JackStraw(object = x,  -->
<!--             assay = "SCT", -->
<!--             num.replicate = 100, -->
<!--             #reduction.name = "pca.LogNorm",  -->
<!--             verbose = TRUE) -->
<!--   ScoreJackStraw(object = x, -->
<!--                  assay = "SCT", -->
<!--                  # reduction.name = "pca.logNorm", -->
<!--                  dims = 1:50) }) -->

<!-- for (i in 1:length(list_obj)) { -->

<!--   obj = list_obj[[i]] -->
<!--   name_obj = names(list_obj)[i] -->

<!--   obj = JackStraw(obj, num.replicate = 100, reduction.name = "pca.LogNorm") -->

<!--   JackStrawPlot(obj, dims = 1:2, reduction = "pca.LogNorm") -->

<!--   logNorm_JS_plot = ElbowPlot(object = obj, ndims = 100, reduction = "pca.LogNorm") +  -->
<!--     geom_vline(xintercept = 30, color = "red", size = 1) +  -->
<!--     ggtitle(name_obj) + -->
<!--     theme(plot.background = element_rect(fill = "white")) -->

<!--   ggsave(plot = logNorm_elb_plot,  -->
<!--          filename = paste0(dir_output, "plot_logNorm_elb_", name_obj, ".png"),  -->
<!--          height = 4, width = 8) -->

<!--   print(logNorm_elb_plot) -->

<!-- } -->

<!-- ``` -->

<!-- ‘Significant’ PCs will show a strong enrichment of features with low p-values (solid curve above the dashed line). In this case it appears that there is a sharp drop-off in significance after the first 10-12 PCs. -->

<!-- composition de la PCA en heatmap  -->
<!-- ```{r, results='hold', fig.width=18, fig.height=10, fig.fullwidth=TRUE} -->

<!-- obj = list_obj[[i]] -->
<!-- DimHeatmap(obj, dims = 1:30, cells = 2000, reduction = "pca.LogNorm", balanced = TRUE) -->
<!-- ``` -->


<!-- # Reduction de dimensions UMAP -->

<!-- ```{r} -->
<!--   obj = RunUMAP(object = obj, dims = 1:30, reduction =  "pca.LogNorm", reduction.name = "umap.LogNorm", verbose = TRUE) -->
<!--   logNorm_umap_plot = DimPlot(object = obj, group.by = "orig.ident", reduction = "umap.LogNorm") + NoLegend() -->
<!--   logNorm_umap_split_plot = DimPlot(object = obj, group.by = "orig.ident", split.by = "orig.ident", reduction = "umap.LogNorm") -->
<!--   ggsave(plot = logNorm_umap_plot|logNorm_umap_split_plot,  -->
<!--          filename = paste0(dir_output, "plot_logNorm_umap_", name_obj, ".png"),  -->
<!--          height = 6, width = 18) -->

<!--   list_obj[[i]] = obj -->
<!-- ``` -->

<!-- Visualisation des graphiques du fichier pour déterminer les dimensions à conserver.  -->
<!-- ```{r  results='hold', fig.width=18, fig.height=10, fig.fullwidth=TRUE} -->

<!-- obj = list_obj[["data_allcond_filter_nbG_pMT_pRB_rmMT"]] -->

<!-- # Affichage des graphiques pour le fichier contenant tous les filtres  -->
<!-- logNorm_pca_plot = DimPlot(object = obj, group.by = "orig.ident", reduction = "pca.LogNorm") +  -->
<!--   NoLegend() +  -->
<!--   ggtitle("data_allcond_filter_nbG_pMT_pRB_rmMT") -->
<!-- logNorm_pca_split_plot = DimPlot(object = obj, group.by = "orig.ident", split.by = "orig.ident", reduction = "pca.LogNorm") -->
<!-- logNorm_elb_plot = ElbowPlot(object = obj, ndims = 100, reduction = "pca.LogNorm") +  -->
<!--     geom_vline(xintercept = 30, color = "red", size = 1) +  -->
<!--     theme(plot.background = element_rect(fill = "white")) -->
<!-- logNorm_umap_plot = DimPlot(object = obj, group.by = "orig.ident", reduction = "umap.LogNorm") + NoLegend() -->
<!-- logNorm_umap_split_plot = DimPlot(object = obj, group.by = "orig.ident", split.by = "orig.ident", reduction = "umap.LogNorm") -->

<!-- (logNorm_pca_plot | logNorm_pca_split_plot) / logNorm_elb_plot / (logNorm_umap_plot | logNorm_umap_split_plot) -->

<!-- ``` -->

<!-- ```{r dimensional_reduction_SCT, results='hold', fig.width=18, fig.height=18, fig.fullwidth=TRUE} -->

<!-- DefaultAssay(obj) <- "SCT" # On définit SCT comme l'assay de travail (c'est déjà le cas normalement)  -->
<!-- obj = RunPCA(object = obj, assay = "SCT", npcs = 100, reduction.name = "pca.sct", verbose = TRUE) -->

<!-- sct_elb_plot = ElbowPlot(obj, ndims = 100, reduction = "pca.sct") + geom_vline(xintercept = 30, color = "red", size = 1) + theme(plot.background = element_rect(fill = "white")) -->
<!-- sct_pca_plot = DimPlot(object = obj, group.by = "orig.ident", reduction = "pca.sct") -->
<!-- sct_pca_split_plot = DimPlot(object = obj, group.by = "orig.ident", split.by = "orig.ident", reduction = "pca.sct") -->

<!-- obj = RunUMAP(object = obj, dims = 1:30, reduction =  "pca.sct", reduction.name = "umap.sct", verbose = TRUE) -->
<!-- sct_umap_plot = DimPlot(object = obj, group.by = "orig.ident", reduction = "umap.sct") -->
<!-- sct_umap_split_plot = DimPlot(object = obj, group.by = "orig.ident", split.by = "orig.ident", reduction = "umap.sct") -->

<!-- (sct_pca_plot | sct_pca_split_plot) / (sct_elb_plot) / (sct_umap_plot | sct_umap_split_plot) -->

<!-- ``` -->

<!-- ```{r} -->
<!-- ggsave(plot = sct_pca_plot|sct_pca_split_plot, filename =  paste0(dir_output, "plot_sct_pca_", str_extract(name_obj, pattern = ".+(?=.rds)"), ".png"), height = 6, width = 18) -->
<!-- ggsave(plot = sct_elb_plot, filename = paste0(dir_output, "plot_sct_elb_", str_extract(name_obj, pattern = ".+(?=.rds)"), ".png"), height = 4, width = 8) -->
<!-- ggsave(plot = sct_umap_plot|sct_umap_split_plot, filename = paste0(dir_output, "plot_sct_umap_", str_extract(name_obj, pattern = ".+(?=.rds)"), ".png"), height = 6, width = 18) -->
<!-- ``` -->



<!-- ## .Visualize cells and features that define the PCA -->

<!-- ```{r, results="hold", fig.width=20, fig.height=20, fig.fullwidth=TRUE} -->
<!-- VizDimLoadings(obj_filtered, dims = 1:10, reduction = "pca.LogNorm") -->
<!-- ``` -->































```{r, Save outputs}

```

```{r, Rsession}

# Clean working space and show package version
rm(list = ls())
sessionInfo()

```
